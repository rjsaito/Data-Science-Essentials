{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjsaito/Data-Science-Essentials/blob/master/Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE5pM_oluMCl",
        "colab_type": "text"
      },
      "source": [
        "# Linear Algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRuPkCOflVGb",
        "colab_type": "text"
      },
      "source": [
        "## Eigenvalues and Eigenvectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VSwqhaOq-8T",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHrWaPTylXC3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "$$\n",
        "A v = \\lambda v\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di4LY-Otq_1y",
        "colab_type": "text"
      },
      "source": [
        "- eigen value \n",
        "- eigen vector\n",
        "- invertibe matrix\n",
        "- singularity\n",
        "- singular values (square root of eigen values)\n",
        "- rank\n",
        "- linear independence\n",
        "- singular value decomposition\n",
        "- eigenvalue decomposition (matrix represented in eigenvalues and eigenvectors)\n",
        "- singular value decomposition (complexity of m^2 n + n^3, or O(mn^2))\n",
        "- matrix factorization (nm)^(O(2^r r^2)) time exact solution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Bh1vWPOIbe",
        "colab_type": "text"
      },
      "source": [
        "## Principal Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0YP9mnJOLRp",
        "colab_type": "text"
      },
      "source": [
        "## Factor Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv2Hjn6-lQaC",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gf9JZgJrKU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEYHDJCDnmJS",
        "colab_type": "text"
      },
      "source": [
        "## Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpQO5LZKnp1n",
        "colab_type": "text"
      },
      "source": [
        "### Cross Entropy (Log Loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4NJUETXnr4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Full function: -(y*log(p) + (1-y)*log(1-p))\n",
        "def CrossEntropy(p, y):\n",
        "  if y == 1:\n",
        "    return -log(p)\n",
        "  else:\n",
        "    return -log(1 - p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZFhvxXNoof-",
        "colab_type": "text"
      },
      "source": [
        "### Hinge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPMQYkyion9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Hinge(p, y):\n",
        "  return np.max(0, 1 - yHat * y)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l9vMafio7AP",
        "colab_type": "text"
      },
      "source": [
        "### Mean Absolute Error (L1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D4sf1b6o8rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MAE(yH, y):\n",
        "  return np.sum(np.absolute(yH - y)) / y.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZszRc3qpHsQ",
        "colab_type": "text"
      },
      "source": [
        "### Mean Squared Error (L2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy2GgxJkpKON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MSE(yH, y):\n",
        "  return np.sum((yH - y)**2) / y.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqmB8fWuOYn",
        "colab_type": "text"
      },
      "source": [
        "## scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2jHO6lOSxji",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG88zDi9ReK1",
        "colab_type": "text"
      },
      "source": [
        "## Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPMR3ksRRgUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d31ad3a0-1519-4e78-8d80-6d29746752f6"
      },
      "source": [
        "# load libraries\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "# load data\n",
        "boston = load_boston()\n",
        "features = boston.data\n",
        "target = boston.target\n",
        "\n",
        "# standardize\n",
        "scalar = StandardScaler()\n",
        "features_standardized = scalar.fit_transform(features)\n",
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G-Pvxf5SZjr",
        "colab_type": "text"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yakAQlX1SdVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# polynomial terms\n",
        "polynomial = PolynomialFeatures(degree = 3, include_bias = False)\n",
        "features_polynomial = polynomial.fit_transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdr2tSMvSs3D",
        "colab_type": "text"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OhZH46SSsJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create regression\n",
        "regression = LinearRegression()\n",
        "\n",
        "# fit model\n",
        "model = regression.fit(features_polynomial, target)\n",
        "\n",
        "# get model output\n",
        "print(model.intercept_)\n",
        "print(model.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzR_EVoTT53",
        "colab_type": "text"
      },
      "source": [
        "### Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZUeihkpTVVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a15c4562-04cf-4345-851e-9448b4b219eb"
      },
      "source": [
        "# create ridge regression, with cross validation\n",
        "ridge = RidgeCV(cv = 5)\n",
        "\n",
        "# fit model\n",
        "ridgemodel = ridge.fit(features, target)\n",
        "\n",
        "# get model output\n",
        "print(ridgemodel.intercept_)\n",
        "print(ridgemodel.coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27.467884964141177\n",
            "[-0.10143535  0.0495791  -0.0429624   1.95202082 -2.37161896  3.70227207\n",
            " -0.01070735 -1.24880821  0.2795956  -0.01399313 -0.79794498  0.01003684\n",
            " -0.55936642]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWCxwVi8Va7Y",
        "colab_type": "text"
      },
      "source": [
        "### Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-tEy6hdVede",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0530986b-cdfc-4b2e-b6e0-3fcfdace126f"
      },
      "source": [
        "# create lasso regression, with cross validation\n",
        "lasso = LassoCV(cv = 5)\n",
        "\n",
        "# fit model\n",
        "lassomodel = lasso.fit(features, target)\n",
        "\n",
        "# get model output\n",
        "print(lassomodel.intercept_)\n",
        "print(lassomodel.coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36.33499969015174\n",
            "[-0.07426626  0.04945448 -0.          0.         -0.          1.804385\n",
            "  0.01133345 -0.81324404  0.27228399 -0.01542465 -0.74287183  0.00892587\n",
            " -0.70365352]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yujHbDEMibn",
        "colab_type": "text"
      },
      "source": [
        "## Tree-Based Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H0rh5cgMj9N",
        "colab_type": "text"
      },
      "source": [
        "- Classification tree analysis is when the predicted outcome is the class (discrete) to which the data belongs.\n",
        "- Regression tree analysis is when the predicted outcome can be considered a real number (e.g. the price of a house, or a patient's length of stay in a hospital).\n",
        "- Boosted trees Incrementally building an ensemble by training each new instance to emphasize the training instances previously mis-modeled. A typical example is AdaBoost. These can be used for regression-type and classification-type problems.[7][8]\n",
        "- Bootstrap aggregated (or bagged) decision trees, an early ensemble method, builds multiple decision trees by repeatedly resampling training data with replacement, and voting the trees for a consensus prediction.[9]\n",
        "  - A random forest classifier is a specific type of bootstrap aggregating\n",
        "- Rotation forest – in which every decision tree is trained by first applying principal component analysis (PCA) on a random subset of the input features.[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6xEOsP9KsvF",
        "colab_type": "text"
      },
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu-zSYa2KydM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Information Gain**\n",
        "\n",
        "Synonym for **Kullback-Leibler diverence** (also called relative entropyt), Information Gain is the amount of information gained about a random variable or signal from observing another random variable.\n",
        "\n",
        "The information gain of a random variable X obtained from an observation of a random variable A taking value A = a is defined:\n",
        "\n",
        "$ {\\displaystyle IG_{X,A}{(X,a)}=D_{\\text{KL}}{\\left(P_{X}{(x|a)}\\|P_{X}{(x|I)}\\right)},} $\n",
        "\n",
        "the Kullback-Leibler diverence of the prior distribution $P_X(x|I) $ for x from the posterior distribution $ P_{x|A}(X|a) $ for x given a\n",
        "\n",
        "\n",
        "In general terms, the expected information gain is the **change in information entropy H** as:\n",
        "\n",
        "$ IG(T, a) = H(T) - H(T|a) $\n",
        "\n",
        "where $ H(T|a) $ is the conditional entropy of T given the value of attribute a\n",
        "\n",
        "\n",
        "$ H(T) - I_E(p_1, p_2, .., p_J) = -\\Sigma^J_{i=1}p_i log_2 p_i $ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hpjbd9YS6Mc",
        "colab_type": "text"
      },
      "source": [
        "## Matrix Factorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjKexvCyS9vv",
        "colab_type": "text"
      },
      "source": [
        "### LibMF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw0w4VbnS_lB",
        "colab_type": "text"
      },
      "source": [
        "https://www.csie.ntu.edu.tw/~cjlin/papers/libmf/libmf_open_source.pdf\n",
        "\n",
        "Non-convex optimization problem:\n",
        "\n",
        "$$ \\underset{P,Q}{min} \\underset{(u,v)\\epsilon R}{\\Sigma} [f(p_u, q_v; r_{u,v}) + \\mu_p || p_u||_1 + \\mu_q ||q_v||_1 +\n",
        "\\frac{λ_p}{2} || p_u ||^2_2 + \\frac{λ_q}{2} ||q_v||^2_2 ]  \\ \\ \\ (1)\n",
        "$$\n",
        "\n",
        "where \n",
        "\n",
        "$f(p_u, q_v; r_{u,v})$ is the loss function, $p_u, q_v$ are latent factors, $r_{u,v}$ is the interaction, and $\\mu_p, \\mu_q, λ_p, λ_q$ are regularization parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz6KLDTlXBd5",
        "colab_type": "text"
      },
      "source": [
        "### Training with Stochastic Gradient Descent\n",
        "\n",
        "The algorithm for the Fast Parallelized Stochastic Gradient Descent is:\n",
        "\n",
        "1. randomly shuffle R\n",
        "2. grid R into a set B with at least (s + 1) × (s + 1) blocks\n",
        "3. sort each block by user (or item) identities\n",
        "4. construct a scheduler\n",
        "5. launch s working threads\n",
        "6. wait until the total number of updates reaches a user-defined value\n",
        "\n",
        "\n",
        "The basic idea of SG is that, instead of expensively calculating the gradient of (1), it randomly selects a $(u,v)$ entry from the summation and calculates the corresponding gradient [Robbins and Monro 1951; Kiefer and Wolfowitz 1952]. Once $r_{u,v}$ is chosen, the objective function in (1), is:\n",
        "\n",
        "$$ f(p_u, q_v; r_{u,v}) + \\mu_p p_u + \\mu_q q_v +\n",
        "\\frac{λ_p}{2} p_u^T p_u + \\frac{λ_q}{2} q_v^T q_v \\ \\ \\ (2)\n",
        "$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "We calculate the sub-gradient over $p_u$ and $q_v$. Variables are updated by the following rules:\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$\n",
        "p_u ← p_u + γ (\\frac{d}{dp_u}(2)),  \\\\\n",
        "q_v ← q_v + γ (\\frac{d}{dq_v}(2))\n",
        "$$\n",
        "\n",
        "where $\\gamma$ is the learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkFNJJX1ZuZ2",
        "colab_type": "text"
      },
      "source": [
        "### Loss Functions\n",
        "\n",
        " $f(·)$ is a non-convex loss function of $p_u$ and $q_v$, and $\\mu_p$, $\\mu_q$, $\\lambda_p$, and $\\lambda_q$ are regularization coefficients. For Real Valued MF, the loss function can be a squared loss, an absolute loss, or generalized KL-divergence. If R is a binary matrix, users may select among logistic loss, hinge loss, and squared hinge loss to perform BMF. Note that, the non-negative constraints,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-avBcjXobjcU",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3a-iNQnrFpT",
        "colab_type": "text"
      },
      "source": [
        "## Two-layer Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdgOGhkirHRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
        "    \"\"\"\n",
        "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (n_x, number of examples)\n",
        "    Y -- true \"label\" vector (containing 1 if cat, 0 if non-cat), of shape (1, number of examples)\n",
        "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
        "    num_iterations -- number of iterations of the optimization loop\n",
        "    learning_rate -- learning rate of the gradient descent update rule\n",
        "    print_cost -- If set to True, this will print the cost every 100 iterations \n",
        "    \n",
        "    Returns:\n",
        "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(1)\n",
        "    grads = {}\n",
        "    costs = []                              # to keep track of the cost\n",
        "    m = X.shape[1]                           # number of examples\n",
        "    (n_x, n_h, n_y) = layers_dims\n",
        "    \n",
        "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
        "    ### START CODE HERE ### (≈ 1 line of code)\n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1, W2, b2\". Output: \"A1, cache1, A2, cache2\".\n",
        "        ### START CODE HERE ### (≈ 2 lines of code)\n",
        "        A1, cache1 = linear_activation_forward(X, W1, b1, activation = \"relu\")\n",
        "        A2, cache2 = linear_activation_forward(A1, W2, b2, activation = \"sigmoid\")\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Compute cost\n",
        "        ### START CODE HERE ### (≈ 1 line of code)\n",
        "        cost = compute_cost(A2, Y)\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Initializing backward propagation\n",
        "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
        "        \n",
        "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
        "        ### START CODE HERE ### (≈ 2 lines of code)\n",
        "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, activation = \"sigmoid\")\n",
        "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, activation = \"relu\")\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
        "        grads['dW1'] = dW1\n",
        "        grads['db1'] = db1\n",
        "        grads['dW2'] = dW2\n",
        "        grads['db2'] = db2\n",
        "        \n",
        "        # Update parameters.\n",
        "        ### START CODE HERE ### (approx. 1 line of code)\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        # Retrieve W1, b1, W2, b2 from parameters\n",
        "        W1 = parameters[\"W1\"]\n",
        "        b1 = parameters[\"b1\"]\n",
        "        W2 = parameters[\"W2\"]\n",
        "        b2 = parameters[\"b2\"]\n",
        "        \n",
        "        # Print the cost every 100 training example\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
        "        if print_cost and i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "       \n",
        "    # plot the cost\n",
        "\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyYLn_gfaJlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia5j8_JaXgnK",
        "colab_type": "text"
      },
      "source": [
        "## **Recurrent Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD6WKlswoCtP",
        "colab_type": "text"
      },
      "source": [
        "#### **Types of Sequence Data**\n",
        "\n",
        "- Speech recognition\n",
        "- Music generation\n",
        "- Sentiment Classification\n",
        "- DNA sequence analysis\n",
        "- Machine translation\n",
        "- Video activitry recognition\n",
        "- Name entity recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNHeKy5vpUzO",
        "colab_type": "text"
      },
      "source": [
        "**Why Standard Networks don't work**\n",
        "\n",
        "If input were one-hot-encoded word vectors:\n",
        "\n",
        "- Inputs, Outputs can be different lengths in different examples\n",
        "- Doesn't share features learned across different positions of text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynGO9Y0zqN2E",
        "colab_type": "text"
      },
      "source": [
        "### **(Unidirectional) RNN**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "- $a^{<0>} = 0$\n",
        "- $\\hat{a}^{<1>} = g_1(w_{aa}a^{<0>} + w_{ax}x^{<1>}+b_a) $  <- tanh/ReLu\n",
        "- $\\hat{y}^{<1>} = g_1(w_{ya}a^{<1>} + b_y) $ <- sigmoid\n",
        "- $\\hat{a}^{<t>} = g_1(w_{aa}a^{<t-1>} + w_{ax}x^{<t>}+b_a) $  \n",
        "- $\\hat{y}^{<t>} = g_1(w_{ya}a^{<t>} + b_y) $ \n",
        "\n",
        "Written otherwise:\n",
        "\n",
        "- $\\hat{a}^{<t>} = g(w_{a}[a^{<t-1>}, x^{<t>}]+b_a) $\n",
        "  - Stack $w_{aa}$ and $w_{ax}$ , compress into one\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMWlZ-d9TmRE",
        "colab_type": "text"
      },
      "source": [
        "### **Bidirectional RNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGuqkRr_Tpc9",
        "colab_type": "text"
      },
      "source": [
        "Bidirectional RNN has a similar structure as the Unidirectional RNN, but with an additional activation at each iteration in reverse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbUXiECsnyb3",
        "colab_type": "text"
      },
      "source": [
        "### **BERT**\n",
        "\n",
        "Called Bidirectional Encoder Representation - applies the bidrectional training of Transformer, a popular attention model. (Technically it is non-directional since it looks at all words simultaneously"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1k5iXSRoA8J",
        "colab_type": "text"
      },
      "source": [
        "**Masked LM (MLM)**\n",
        "\n",
        "Before feeding word sequences into BERT (tokenized and encoded), 15% of words in each sequence are replaced with a [MASK] token. The model then attemps to predict the original value of the masked words, basde on the context provided by other non-masked words in the sequence\n",
        "\n",
        "The prediction of the output words requires:\n",
        "1. adding a classification layer on top of the encoder output\n",
        "2. Multiplying the output vectors by the embedding matrix, transforming them into the vocabulaty dimension\n",
        "3. Calculating the probability of each word in the vocabulary with softmax\n",
        "\n",
        "The BERT loss function takes into consideration only the prediction of the masked values and ignores the prediction of the non-masked words.\n",
        "\n",
        "As a consequence, the model coverages slower than directional models, a characteristic which is offest by its increased context awareness\n",
        "\n",
        "**Next Sentence Prediction (NSP)**\n",
        "\n",
        "In the BERT training process, the model receives pairs of sentences as input and learns to predict if the second sentencei n the pair is the subsequent sentence in the original document. During training, 50% of the inputs are a pair in which the second sentence is ther subsequent sentence in the original document, while in the other 50% a random sentence from the corpus is chosen as the second sentence. The assumption is that the random sentence will be disconnected from the first sentence.\n",
        "\n",
        "How input is processed before entering the model:\n",
        "1. A [CLS] token is inserted at the beginning of the first sentenfce and a [SEP] token is inserted at the end of each sentence\n",
        "2. A sentence embedding indicating Sentence A or Sentence B is added to each token. Sentence embeddings are similar in concept to token embeddings with a vocabulary of 2\n",
        "3. A positional embedding is added to each token to indicate its position in the sequence. The concept and implementation of positional embedding are presented in the Transformer paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j3eyx_jnwmD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCEC_wFz4bw3",
        "colab_type": "text"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydPWDMJf4hPH",
        "colab_type": "text"
      },
      "source": [
        "#### Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdhB21Wn2zov",
        "colab_type": "text"
      },
      "source": [
        "RNN for Short-Term Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtD9RRf0Xj-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "print(\"Tensorflow version: \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCr691hT3Bnx",
        "colab_type": "text"
      },
      "source": [
        "Generate Fake Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DIlFYT83A3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_SEQ_LEN = 1024*128\n",
        "data = np.concatenate([create_time_series(waveform, DATA_SEQ_LEN) for waveform in Waveforms]) # 4 different wave forms\n",
        "picture_this_1(data, DATA_SEQ_LEN)\n",
        "DATA_LEN = DATA_SEQ_LEN * 4 # since we concatenated 4 sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmZ1kGsi3FEx",
        "colab_type": "text"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBh1cUHS3GGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RNN_CELLSIZE = 32   # size of the RNN cells\n",
        "SEQLEN = 32         # unrolled sequence length\n",
        "BATCHSIZE = 32      # mini-batch size\n",
        "LAST_N = SEQLEN//2  # loss computed on last N element of sequence in advanced RNN model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkWC9wPP3JBA",
        "colab_type": "text"
      },
      "source": [
        "Visualize Training Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5aFmYH3KFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "picture_this_2(data, BATCHSIZE, SEQLEN) # execute multiple times to see different sample sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl4HORqh3OJ1",
        "colab_type": "text"
      },
      "source": [
        "Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CobkBsfj3P08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is how to create a Keras model from neural network layers\n",
        "def compile_keras_sequential_model(list_of_layers, msg):\n",
        "  \n",
        "    # a tf.keras.Sequential model is a sequence of layers\n",
        "    model = tf.keras.Sequential(list_of_layers)\n",
        "    \n",
        "    # keras does not have a pre-defined metric for Root Mean Square Error. Let's define one.\n",
        "    def rmse(y_true, y_pred): # Root Mean Squared Error\n",
        "      return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
        "    \n",
        "    print('\\nModel ', msg)\n",
        "    \n",
        "    # to finalize the model, specify the loss, the optimizer and metrics\n",
        "    model.compile(\n",
        "       loss = 'mean_squared_error',\n",
        "       optimizer = 'rmsprop',\n",
        "       metrics = [rmse])\n",
        "    \n",
        "    # this prints a description of the model\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "  \n",
        "#\n",
        "# three very simplistic \"models\" that require no training. Can you beat them ?\n",
        "#\n",
        "\n",
        "# SIMPLISTIC BENCHMARK MODEL 1\n",
        "predict_same_as_last_value = lambda x: x[:,-1] # shape of x is [BATCHSIZE,SEQLEN]\n",
        "# SIMPLISTIC BENCHMARK MODEL 2\n",
        "predict_trend_from_last_two_values = lambda x: x[:,-1] + (x[:,-1] - x[:,-2])\n",
        "# SIMPLISTIC BENCHMARK MODEL 3\n",
        "predict_random_value = lambda x: tf.random.uniform(tf.shape(x)[0:1], -2.0, 2.0)\n",
        "\n",
        "def model_layers_from_lambda(lambda_fn, input_shape, output_shape):\n",
        "  return [tf.keras.layers.Lambda(lambda_fn, input_shape=input_shape),\n",
        "          tf.keras.layers.Reshape(output_shape)]\n",
        "\n",
        "model_layers_RAND  = model_layers_from_lambda(predict_random_value,               input_shape=[SEQLEN,], output_shape=[1,])\n",
        "model_layers_LAST  = model_layers_from_lambda(predict_same_as_last_value,         input_shape=[SEQLEN,], output_shape=[1,])\n",
        "model_layers_LAST2 = model_layers_from_lambda(predict_trend_from_last_two_values, input_shape=[SEQLEN,], output_shape=[1,])\n",
        "\n",
        "# three neural network models for comparison, in increasing order of complexity\n",
        "\n",
        "l = tf.keras.layers  # syntax shortcut\n",
        "\n",
        "# BENCHMARK MODEL 4: linear model (RMSE: 0.215 after 10 epochs)\n",
        "model_layers_LINEAR = [l.Dense(1, input_shape=[SEQLEN,])] # output shape [BATCHSIZE, 1]\n",
        "\n",
        "# BENCHMARK MODEL 5: 2-layer dense model (RMSE: 0.197 after 10 epochs)\n",
        "model_layers_DNN = [l.Dense(SEQLEN//2, activation='relu', input_shape=[SEQLEN,]), # input  shape [BATCHSIZE, SEQLEN]\n",
        "                    l.Dense(1)] # output shape [BATCHSIZE, 1]\n",
        "\n",
        "# BENCHMARK MODEL 6: convolutional (RMSE: 0.186 after 10 epochs)\n",
        "model_layers_CNN = [\n",
        "    l.Reshape([SEQLEN, 1], input_shape=[SEQLEN,]), # [BATCHSIZE, SEQLEN, 1] is necessary for conv model\n",
        "    l.Conv1D(filters=8, kernel_size=4, activation='relu', padding=\"same\"), # [BATCHSIZE, SEQLEN, 8]\n",
        "    l.Conv1D(filters=16, kernel_size=3, activation='relu', padding=\"same\"), # [BATCHSIZE, SEQLEN, 8]\n",
        "    l.Conv1D(filters=8, kernel_size=1, activation='relu', padding=\"same\"), # [BATCHSIZE, SEQLEN, 8]\n",
        "    l.MaxPooling1D(pool_size=2, strides=2),  # [BATCHSIZE, SEQLEN//2, 8]\n",
        "    l.Conv1D(filters=8, kernel_size=3, activation='relu', padding=\"same\"),  # [BATCHSIZE, SEQLEN//2, 8]\n",
        "    l.MaxPooling1D(pool_size=2, strides=2),  # [BATCHSIZE, SEQLEN//4, 8]\n",
        "    # mis-using a conv layer as linear regression :-)\n",
        "    l.Conv1D(filters=1, kernel_size=SEQLEN//4, activation=None, padding=\"valid\"), # output shape [BATCHSIZE, 1, 1]\n",
        "    l.Reshape([1,]) ] # output shape [BATCHSIZE, 1]\n",
        "\n",
        "# RNN\n",
        "model_layers_RNN = [\n",
        "    # input shape needed on first layer only\n",
        "    l.Reshape([SEQLEN, 1], input_shape=[SEQLEN,]),\n",
        "    l.GRU(RNN_CELLSIZE), # shape [BATCHSIZE, RNN_CELLSIZE]\n",
        "    l.Dense(1, ) # shape [BATCHSIZE, 1]\n",
        "    \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLdkfDMu4nDI",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw0rFkuUDGNT",
        "colab_type": "text"
      },
      "source": [
        "#### **Types of CV Problems**\n",
        "\n",
        "- Image Classifcation\n",
        "- Object Detection\n",
        "- Neural Style Transfer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ineuf_hDdOV",
        "colab_type": "text"
      },
      "source": [
        "#### **Edge Detection**\n",
        "\n",
        "Edges are detected using Filters (or Kernels)\n",
        "- In Tensorflow: tf.nn.conv2d\n",
        "- In Keras: Cond2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAISj84XEMF0",
        "colab_type": "text"
      },
      "source": [
        "Horizontal Edge Detection (3x3 filter)\n",
        "\n",
        "|  1,  1,  1 | <br/>\n",
        "|  0,  0,  0 | <br/>\n",
        "| -1, -1, -1 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfsYm49XEOLG",
        "colab_type": "text"
      },
      "source": [
        "Vertical Edge Detection (3x3 filter)\n",
        "\n",
        "| 1, 0, -1 | <br/>\n",
        "| 1, 0, -1 | <br/>\n",
        "| 1, 0, -1 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-WVHzxZE2Qi",
        "colab_type": "text"
      },
      "source": [
        "Sobol Filter (3x3)\n",
        "- More robust (vertical) detector with higher weight in the center\n",
        "\n",
        "| 1, 0, -1 | <br/>\n",
        "| 2, 0, -2 | <br/>\n",
        "| 1, 0, -1 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxokzfBsFSn4",
        "colab_type": "text"
      },
      "source": [
        "#### **Padding**\n",
        "\n",
        "Padding is used to ensure the input array size matches the output (so as not to lose the edge pixels)\n",
        "\n",
        "Two Types of Convolution:\n",
        "- Valid: no filter (nxn * fxf -> [n - f + 1] x [n - f + 1])\n",
        "- Same: pad so output size is the same as input (padding p = (f - 1) / 2)\n",
        "\n",
        "*Note: f is usually odd (1x1, 3x3, 5x5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSgFfaRCGUUJ",
        "colab_type": "text"
      },
      "source": [
        "#### **Strided Convolution**\n",
        "\n",
        "Stride is the # of steps (pixels) to move over at each filter iteration (vertically and horizontally)\n",
        "\n",
        " (nxn * fxf, stride s = 2  -> [(n + 2p - f)/s + 1] x [(n + 2p - f)/s + 1] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20pJrd_hHw9R",
        "colab_type": "text"
      },
      "source": [
        "#### **Convolution on RGB images**\n",
        "\n",
        "Your input may look like 6 x 6 x 3 (height x width x color channels)\n",
        "\n",
        "Your convolution (filter) may then be a 3 x 3 x 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJHGuTNnJufn",
        "colab_type": "text"
      },
      "source": [
        "#### **Pooling Layers**\n",
        "\n",
        "Pooling will abstract or summarise your input (bring down to lower resolution)\n",
        "\n",
        "Types of Pooling:\n",
        "- Max Pooling\n",
        "- Average Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPuaWnOeK6HB",
        "colab_type": "text"
      },
      "source": [
        "#### **Why use Convolution?**\n",
        "\n",
        "- **Parameter sharing**: A feature detector (such as vertical edge detector) that's useful in one part of the iomage is probably useful in another part of the image\n",
        "- **Sparsity of connections**: In each layer, each output value depends only on a small number of inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg_tdgwaRPwP",
        "colab_type": "text"
      },
      "source": [
        "#### **\\# of Parameters and Shape**\n",
        "\n",
        "- Conv Layer:\n",
        "  - \\# Parameters: ([ width m ] x [ height n ] x [prev layer's filters d] + bias 1) * [k filters in current layer)\n",
        "  - Shape: [(n + 2 \\* padding - filters)/stride + 1] x [(n + 2 \\* padding - filters)/stride + 1] x ? )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkjR00-KVDhL",
        "colab_type": "text"
      },
      "source": [
        "| Type | Dimensions |\n",
        "|--|--|\n",
        "| Input | nh[L-1] x nw[L-1] x nc[L-1]|\n",
        "| Activation a[l] | nh[L] x nw[L] x nc[L] |\n",
        "| Weights | f[L] x f[L] x nc[L-1] x nc[L]|\n",
        "| Bias | nc[L]|\n",
        "\n",
        "Where\n",
        "- f[L] = filter size\n",
        "- p[L] = padding\n",
        "- s]L] = stride\n",
        "- nc[L] = number of filters\n",
        "- nc[L-1] = color channels\n",
        "\n",
        "https://engmrk.com/convolutional-neural-network-3/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgNbYk6r4oyT",
        "colab_type": "text"
      },
      "source": [
        "### **Classic Architectures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhgSXoJoOB3",
        "colab_type": "text"
      },
      "source": [
        "**LeNet-5 (1998)**\n",
        "\n",
        "1. Convolution 6 [5x5] (s = 1)\n",
        "2. Avg Pooling (f = 2, s = 2)\n",
        "3. Convolution 16 [5x5] (s = 1)\n",
        "4. Avg Pooling (f = 2, s = 2)\n",
        "5. Dense Layer (120 nodes)\n",
        "6. Dense Layer (84 nodes)\n",
        "7. Softmax (10-way)\n",
        "\n",
        "~60K parameters\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chRLnXbao8Up",
        "colab_type": "text"
      },
      "source": [
        "**AlexNet (2012)**\n",
        "\n",
        "0. Start: 227x227x3\n",
        "1. Convolution 96 [11x11] (s = 4)\n",
        "2. Max Pooling (f = 3, s = 2)\n",
        "3. Convolution 256 [5x5] (same)\n",
        "3. Max Pooling (f = 3, s = 2)\n",
        "5. Convolution 384 [3x3] (same)\n",
        "6. Convolution 384 [3x3] (same)\n",
        "7. Convolution 256 [3x3] (same)\n",
        "8. Max Pooling (f = 3, s = 2)\n",
        "9. Dense (4096)\n",
        "10. Dense (4096)\n",
        "11. Softmax (1000)\n",
        "\n",
        "~60M parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNANLopZccs-",
        "colab_type": "text"
      },
      "source": [
        "**VGG-16 (2015)**\n",
        "\n",
        "Key Features:\n",
        "- Conv = [3x3] (s = 1, same padding)\n",
        "- All Max Pooling [2x2] w/ stride = 2\n",
        "\n",
        "0. Start: 224x224x3\n",
        "1. Convolution 64x2 (2 times) [2x2] (same)\n",
        "2. Max Pooling (f = 2, s = 2)\n",
        "3. Convolution 128x2 (s = 1, same)\n",
        "4. Max Pooling (f = 2, s = 2)\n",
        "5. Convolution 256x3 (s = 1, same)\n",
        "6. Max Pooling (f = 2, s = 2)\n",
        "7. Convolution 512x3 (s = 1, same)\n",
        "8. Max Pooling (f = 2, s = 2)\n",
        "9. Convolution 512x3 (s = 1, same)\n",
        "10. Max Pooling (f - 2, s = 2)\n",
        "11. Dense (4096)\n",
        "12. Dense (4096)\n",
        "13. Softmax (1000)\n",
        "\n",
        "~138M parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhIaIgz_eKG_",
        "colab_type": "text"
      },
      "source": [
        "**ResNet (2015)**\n",
        "\n",
        "**Key Features**:\n",
        "- Utilizes Skip Networks \n",
        "- Utilizes Residuial block\n",
        "- BY training w/ Residual Block, training error does NOT increase with more layers\n",
        "\n",
        "**Residual Block**\n",
        "- Start w/ block A\n",
        "- Linear Operator (z = WA + b)\n",
        "- ReLu (A[L+1] = g(z))\n",
        "- Linear Operator (z2 = WA[L+1] + b)\n",
        "- ReLu w shortcut A (A[L+2] = g(z2 + A))\n",
        "\n",
        "**Identity Block**\n",
        "\n",
        "A standard block, corresponds to the case where the input activation (a[L]) has the same dimension as the output activation (a[L+2 or L+3]) (skipping over 2 or 3 layers)\n",
        "\n",
        "- Start with A\n",
        "- (1) Conv2D(F1, [1x1], valid padding)\n",
        "- (1) Batch Norm\n",
        "- (1) ReLu\n",
        "- (2) Conv2D(F2, [1x1], valid padding)\n",
        "- (2) Batch Norm\n",
        "- (2) ReLu\n",
        "- (3) Conv2D (F3, [1x1], valid padding\n",
        "- (3) Batch Norm\n",
        "- X_shortcut added to ^ output (Add()([var2,var2])\n",
        "- ReLu\n",
        "\n",
        "**Convolution Block**\n",
        "\n",
        "Another block type - use when input and output dimensions don't match up. The difference is that convolution is applied to the shortcut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNnnYEefcHxr",
        "colab_type": "text"
      },
      "source": [
        "#### **Example ResNet-50 Model**\n",
        "\n",
        "The details of this ResNet-50 model are:\n",
        "\n",
        "- Zero-padding pads the input with a pad of (3,3)\n",
        "- Stage 1 (1 layer):\n",
        "  - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). Its name is \"conv1\".\n",
        "  - BatchNorm is applied to the 'channels' axis of the input.\n",
        "  - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
        "- Stage 2 (9 layers (1x3 + 2x3)):\n",
        "  - The convolutional block uses three sets of filters of size [64,64,256], \"f\" is 3, \"s\" is 1 and the block is \"a\".\n",
        "  - The 2 identity blocks use three sets of filters of size [64,64,256], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
        "- Stage 3 (12 layers (1x3 + 3x3)):\n",
        "  - The convolutional block uses three sets of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
        "  - The 3 identity blocks use three sets of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\".\n",
        "- Stage 4 (18 layers 1x3 + 5x3)):\n",
        "  - The convolutional block uses three sets of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
        "  - The 5 identity blocks use three sets of filters of size [256, 256, 1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n",
        "- Stage 5 (10 layers (3x3 + 1)):\n",
        "  - The convolutional block uses three sets of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
        "  - The 2 identity blocks use three sets of filters of size [512, 512, 2048], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
        "  - The 2D Average Pooling uses a window of shape (2,2) and its name is \"avg_pool\".\n",
        "  - The 'flatten' layer doesn't have any hyperparameters or name.\n",
        "  - The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation. Its name should be 'fc' + str(classes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR-Qrkmo5q8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D(pool_size=(2,2), name=\"avg_pool\")(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSnZgb2XxN-Q",
        "colab_type": "text"
      },
      "source": [
        "**Inception Network (2014)**\n",
        "\n",
        "Inception Networks are used to apply different convolutions at an activation step, and concatenate all the outputs into one layer (channel concatenation)\n",
        "\n",
        "Motivation: significantly reduces # of parameters needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_yL2QGAzuG3",
        "colab_type": "text"
      },
      "source": [
        "### **Data Augmentation**\n",
        "\n",
        "Motivation for Data Augmentation: Increase training data size\n",
        "\n",
        "Methods:\n",
        "- Mirroring\n",
        "- Random Cropping (identity, rotating, or sheering)\n",
        "- Color Shifting (RGB) (scalar or PCA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSWXDeThQOkM",
        "colab_type": "text"
      },
      "source": [
        "### **Bias and Variance**\n",
        "\n",
        "How to reduce Bias:\n",
        "- More training data\n",
        "\n",
        "How to reduce Variance:\n",
        "- Deeper Network\n",
        "- Regularization (dropout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x1CzBZcXB3U",
        "colab_type": "text"
      },
      "source": [
        "### **Problem with Deep Networks**\n",
        "\n",
        "1. Vanishing / Exploding Gradients\n",
        "- as you backprop from the final layer to the first layer, multiplying by the weight matrix on each step can cause the gradient to decrease / increase exponentially quickly \n",
        "- addressed using Batch Normalization or using Skip Connections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lILPZx0i4SoZ",
        "colab_type": "text"
      },
      "source": [
        "### **Object Localization**\n",
        "\n",
        "Most Image Classification Tasks require Classification with Localization (or Detection for multiple objects)\n",
        "\n",
        "In general for localization tasks, the final layer will output the classes + the points of the bounding box (of the object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uECOUE6W6Cd9",
        "colab_type": "text"
      },
      "source": [
        "#### **Defining the target label y**\n",
        "\n",
        "For a multi-class object detetection problem, the y label may look like:\n",
        "\n",
        "y = [pc, bx, by, bh, bw, c1, c2, c3]\n",
        "\n",
        "Where\n",
        "- pc: is there any object?\n",
        "- bx: coordinates of the object\n",
        "- by: coordinates of the object\n",
        "- bh: coordinates of the object\n",
        "- bw: coordinates of the object\n",
        "- c1: is it class 1?\n",
        "- c2: is it class 2?\n",
        "- c3: is it class 3?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_QbGh2b7bWa",
        "colab_type": "text"
      },
      "source": [
        "#### **Landmark Detection**\n",
        "\n",
        "Landmarks are objects you want defined with an image (e.g. for a face recognition task, a landmark may be eyes, mouth, nose, etc - and you may want to point out multiple points along each object)\n",
        "\n",
        "Each x-y coordinate on the landmark becomes a labeled point\n",
        "\n",
        "E.g. if you have 64 landmark points, then you have 64x2 points + 1 indicator point = 129 labels\n",
        "\n",
        "*Used widely in AR (e.g. Snapchat Filters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuwg7Dfi8n_5",
        "colab_type": "text"
      },
      "source": [
        "#### **Sliding Windows Detection**\n",
        "\n",
        "If you have cropped images of your object, you can use a sliding window to iterate through every position in the image to find the object\n",
        "\n",
        "You might use different window sizes and iterate through the image multiple times\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI1dOBON9olJ",
        "colab_type": "text"
      },
      "source": [
        "#### **Dense Layers as Convolution Layers**\n",
        "\n",
        "A Dense (or Fully Connected) layer can be converted into a Convolution Layer by the following:\n",
        "\n",
        "Example\n",
        "- Previous Layer: [5 x 5 x 16] tensor\n",
        "- You want to replace a Dense Layer w/ 400 Nodes\n",
        "- Replace with a [5 x 5] kernel with f = 400\n",
        "- Output is a [1 x 1 x 400]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8UcuPh6_HC6",
        "colab_type": "text"
      },
      "source": [
        "### **YOLO (You only look once) (2015)**\n",
        "\n",
        "Key Feature:\n",
        "- Only need to iterate through the image once to find the object\n",
        "\n",
        "**Labels for training**\n",
        "\n",
        "For each grid cell (sliding windows):\n",
        "- y = [pc, bx, by, bh, bw, c1, c2, c3]\n",
        "- if you have 3x3 grid cells: target output is [3 x 3 x 8]\n",
        "\n",
        "\n",
        "**Specifying the position**\n",
        "\n",
        "for each grid cell: top left is (0,0) and bot right is (1,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GpLrZirBcZ7",
        "colab_type": "text"
      },
      "source": [
        "#### **Intersection over Union**\n",
        "\n",
        "Sliding windows may not always perfectly encapsulate an object (i.e localize it)\n",
        "\n",
        "The Intersection of Union calculates the [size of intersection] / [size of union of window and object]\n",
        "\n",
        "Typically, if IoU >= 0.5, then deem as \"correct\" (can be some other threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkPuMNHFCp--",
        "colab_type": "text"
      },
      "source": [
        "#### **Non-max suppression**\n",
        "\n",
        "When an object spans multiple windows, multiple bounding boxes may be detected. Simply find the one with the highest overlap, and remove the rest\n",
        "\n",
        "In Code:\n",
        "- For each output prediction: Discard all boxes with pc <= 0.6\n",
        "- While there are any remaining boxes:\n",
        "  - Pick the box with the largest pc, output as prediction\n",
        "  - Discard any remaining box with IoU >= 0.5 with the box output in the previous step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSsDLwoDDlJI",
        "colab_type": "text"
      },
      "source": [
        "#### **Anchor Boxes**\n",
        "\n",
        "When you have overlapping objects with the same (or similar) mid point, non-max suppression may remove one of the valid objects.\n",
        "\n",
        "How to use Anchor Boxes:\n",
        "- when you have 2 overlapping objects:\n",
        "- a sample y is concatenated with the 2 objects\n",
        "  - e.g. y = [pc, bx, by, bh, bw, c1, c2, c3, pc, bx, by, bh, bw, c1, c2, c3]\n",
        "  - output may look like [3 x 3 x 16]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKJrAOkluY2k",
        "colab_type": "text"
      },
      "source": [
        "### **Face Recognition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9WfuV6Vuw3o",
        "colab_type": "text"
      },
      "source": [
        "Two kinds of task:\n",
        "\n",
        "**Face Verification**\n",
        "- Input: Image, Name ID\n",
        "- Output: whether or not the imput image is that of the claimed person\n",
        "- 1:1 task (easy)\n",
        "\n",
        "**Face Recognition**\n",
        "- Has a database of K persons\n",
        "- Input: image\n",
        "- Output: ID if the image is any of the K persons (or \"not recognized\")\n",
        "- 1:K task (difficult)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvmBHhzrvTte",
        "colab_type": "text"
      },
      "source": [
        "#### **One Shot Learning**\n",
        "\n",
        "Learning from one example to recognize the person again (typically you only have 1 training sample)\n",
        "\n",
        "Also - every time you want to add a new face, if using a DL, you need to add one more node to the softmax layer (retraining every time does not work well)\n",
        "\n",
        "Instead -> learn a \"similarity\" function -> d(img1, img2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7Y_dvalwQnJ",
        "colab_type": "text"
      },
      "source": [
        "#### **Siamese Network (2014)**\n",
        "\n",
        "- Input: Image\n",
        "- Use sequence of Conv, Pooling, and FC Layers\n",
        "- Obtain the encoding (embedding vector) (f(x(1))\n",
        "- $ d(x^{(1)}, x^{(2)}) = || f(x(^{1)}) - f(x^{(2)}) ||^2 $\n",
        "- Learning parameters such that:\n",
        "  - if x(i) and x(i) are the same person, || f(x(1)) - f(x(2)) ||2 is small\n",
        "  - if x(i) and x(i) are diffferent people, || f(x(1)) - f(x(2)) ||2 is large\n",
        "- We can do this using the Triplet Loss (Anchor, Positive, Negative)\n",
        "- $$ L(A, P, N) = max(||f(A) - f(P)||^2 - ||f(A) - f(N)||^2 + \\alpha (margin), 0) $$\n",
        "- Note: Choose triplets that are \"hard\" to train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aGaVqe8yWIQ",
        "colab_type": "text"
      },
      "source": [
        "#### **Face Verification and Binary Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOwzSSz_ybKL",
        "colab_type": "text"
      },
      "source": [
        "Face Verification problem can be treated as a Binary Classification problem (1:1 mapping)\n",
        "\n",
        "Input: 2 images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSzBsodey4Vh",
        "colab_type": "text"
      },
      "source": [
        "### **Neural Style Transfer**\n",
        "\n",
        "Input: Content C, Style S\n",
        "\n",
        "Output: Generated Image G (Content C in Style S)\n",
        "\n",
        "Cost Function\n",
        "$$ J(G) = \\alpha  J_{content}(C, G) + \\beta  J_{style}(S, G)$$\n",
        "\n",
        "\n",
        "Steps:\n",
        "1. Initiage G randomly (white noise)\n",
        "  - G: 100 x 100 x 3 (RGB)\n",
        "2. Use gradient descent to minimize J(G)\n",
        "  - $ G := G - \\frac{d}{dg} J(G)$\n",
        "\n",
        "**Content Cost Function**\n",
        "\n",
        "- Say you use hidden layer l to compute content cost\n",
        "- Use pre-trained ConvNet (e.g. VGG network)\n",
        "- Let a\\[l](C) and a\\[l](G) be the activation of layer l on the images\n",
        "- If  a\\[l](C) and a\\[l](G) are similar, both images have similar content\n",
        "\n",
        "$$ J_{content}(C, G) = \\frac{1}{2} ||a^{[l](C)} - a^{[l](G)}||^2 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNTOO5C2wR3",
        "colab_type": "text"
      },
      "source": [
        "**Style Cost Function**\n",
        "\n",
        "- Say you are using layer l's activation to measure \"style\"\n",
        "- Define style as **correlation** between activations across channels\n",
        "- Let a_(i,j,k)[l] = activation at (i=H,j=W,k=C). G[l] is n_c[l] x n_c[l]\n",
        "\n",
        "\n",
        "\n",
        "$$ J_{style}^{[l]}(S,G) = \\frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})^2}\\Sigma_k \\Sigma_{k'}(G_{kk'}^{[l](S)} - G_{kk'}^{[l](G)})  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gqTKN-O5o09",
        "colab_type": "text"
      },
      "source": [
        "### **Conv 3D**\n",
        "\n",
        "- In 3D, you will have height, width and depth (e.g. 14 x 14 x 14)\n",
        "- Filters are also 3D (5 x 5 x 5)\n",
        "(14 x 14 x 14 x 1) x (5 x 5 x 5 x 1) x 16 filters = 10 x 10 x 10 x 16\n"
      ]
    }
  ]
}