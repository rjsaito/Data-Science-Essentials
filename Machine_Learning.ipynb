{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjsaito/Data-Science-Essentials/blob/master/Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE5pM_oluMCl",
        "colab_type": "text"
      },
      "source": [
        "# Linear Algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRuPkCOflVGb",
        "colab_type": "text"
      },
      "source": [
        "## Eigenvalues and Eigenvectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VSwqhaOq-8T",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHrWaPTylXC3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "$$\n",
        "A v = \\lambda v\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di4LY-Otq_1y",
        "colab_type": "text"
      },
      "source": [
        "- eigen value \n",
        "- eigen vector\n",
        "- invertibe matrix\n",
        "- singularity\n",
        "- singular values (square root of eigen values)\n",
        "- rank\n",
        "- linear independence\n",
        "- singular value decomposition\n",
        "- eigenvalue decomposition (matrix represented in eigenvalues and eigenvectors)\n",
        "- singular value decomposition (complexity of m^2 n + n^3, or O(mn^2))\n",
        "- matrix factorization (nm)^(O(2^r r^2)) time exact solution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Bh1vWPOIbe",
        "colab_type": "text"
      },
      "source": [
        "## Principal Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0YP9mnJOLRp",
        "colab_type": "text"
      },
      "source": [
        "## Factor Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv2Hjn6-lQaC",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gf9JZgJrKU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEYHDJCDnmJS",
        "colab_type": "text"
      },
      "source": [
        "## Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpQO5LZKnp1n",
        "colab_type": "text"
      },
      "source": [
        "### Cross Entropy (Log Loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4NJUETXnr4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Full function: -(y*log(p) + (1-y)*log(1-p))\n",
        "def CrossEntropy(p, y):\n",
        "  if y == 1:\n",
        "    return -log(p)\n",
        "  else:\n",
        "    return -log(1 - p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZFhvxXNoof-",
        "colab_type": "text"
      },
      "source": [
        "### Hinge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPMQYkyion9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Hinge(p, y):\n",
        "  return np.max(0, 1 - yHat * y)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l9vMafio7AP",
        "colab_type": "text"
      },
      "source": [
        "### Mean Absolute Error (L1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D4sf1b6o8rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MAE(yH, y):\n",
        "  return np.sum(np.absolute(yH - y)) / y.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZszRc3qpHsQ",
        "colab_type": "text"
      },
      "source": [
        "### Mean Squared Error (L2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy2GgxJkpKON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MSE(yH, y):\n",
        "  return np.sum((yH - y)**2) / y.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqmB8fWuOYn",
        "colab_type": "text"
      },
      "source": [
        "## scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2jHO6lOSxji",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG88zDi9ReK1",
        "colab_type": "text"
      },
      "source": [
        "## Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPMR3ksRRgUT",
        "colab_type": "code",
        "outputId": "d31ad3a0-1519-4e78-8d80-6d29746752f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load libraries\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "# load data\n",
        "boston = load_boston()\n",
        "features = boston.data\n",
        "target = boston.target\n",
        "\n",
        "# standardize\n",
        "scalar = StandardScaler()\n",
        "features_standardized = scalar.fit_transform(features)\n",
        "features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G-Pvxf5SZjr",
        "colab_type": "text"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yakAQlX1SdVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# polynomial terms\n",
        "polynomial = PolynomialFeatures(degree = 3, include_bias = False)\n",
        "features_polynomial = polynomial.fit_transform(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdr2tSMvSs3D",
        "colab_type": "text"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OhZH46SSsJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create regression\n",
        "regression = LinearRegression()\n",
        "\n",
        "# fit model\n",
        "model = regression.fit(features_polynomial, target)\n",
        "\n",
        "# get model output\n",
        "print(model.intercept_)\n",
        "print(model.coef_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzR_EVoTT53",
        "colab_type": "text"
      },
      "source": [
        "### Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZUeihkpTVVa",
        "colab_type": "code",
        "outputId": "a15c4562-04cf-4345-851e-9448b4b219eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# create ridge regression, with cross validation\n",
        "ridge = RidgeCV(cv = 5)\n",
        "\n",
        "# fit model\n",
        "ridgemodel = ridge.fit(features, target)\n",
        "\n",
        "# get model output\n",
        "print(ridgemodel.intercept_)\n",
        "print(ridgemodel.coef_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27.467884964141177\n",
            "[-0.10143535  0.0495791  -0.0429624   1.95202082 -2.37161896  3.70227207\n",
            " -0.01070735 -1.24880821  0.2795956  -0.01399313 -0.79794498  0.01003684\n",
            " -0.55936642]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWCxwVi8Va7Y",
        "colab_type": "text"
      },
      "source": [
        "### Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-tEy6hdVede",
        "colab_type": "code",
        "outputId": "0530986b-cdfc-4b2e-b6e0-3fcfdace126f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# create lasso regression, with cross validation\n",
        "lasso = LassoCV(cv = 5)\n",
        "\n",
        "# fit model\n",
        "lassomodel = lasso.fit(features, target)\n",
        "\n",
        "# get model output\n",
        "print(lassomodel.intercept_)\n",
        "print(lassomodel.coef_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36.33499969015174\n",
            "[-0.07426626  0.04945448 -0.          0.         -0.          1.804385\n",
            "  0.01133345 -0.81324404  0.27228399 -0.01542465 -0.74287183  0.00892587\n",
            " -0.70365352]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hpjbd9YS6Mc",
        "colab_type": "text"
      },
      "source": [
        "## Matrix Factorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjKexvCyS9vv",
        "colab_type": "text"
      },
      "source": [
        "### LibMF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw0w4VbnS_lB",
        "colab_type": "text"
      },
      "source": [
        "https://www.csie.ntu.edu.tw/~cjlin/papers/libmf/libmf_open_source.pdf\n",
        "\n",
        "Non-convex optimization problem:\n",
        "\n",
        "$$ \\underset{P,Q}{min} \\underset{(u,v)\\epsilon R}{\\Sigma} [f(p_u, q_v; r_{u,v}) + \\mu_p || p_u||_1 + \\mu_q ||q_v||_1 +\n",
        "\\frac{λ_p}{2} || p_u ||^2_2 + \\frac{λ_q}{2} ||q_v||^2_2 ]  \\ \\ \\ (1)\n",
        "$$\n",
        "\n",
        "where \n",
        "\n",
        "$f(p_u, q_v; r_{u,v})$ is the loss function, $p_u, q_v$ are latent factors, $r_{u,v}$ is the interaction, and $\\mu_p, \\mu_q, λ_p, λ_q$ are regularization parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz6KLDTlXBd5",
        "colab_type": "text"
      },
      "source": [
        "### Training with Stochastic Gradient Descent\n",
        "\n",
        "The algorithm for the Fast Parallelized Stochastic Gradient Descent is:\n",
        "\n",
        "1. randomly shuffle R\n",
        "2. grid R into a set B with at least (s + 1) × (s + 1) blocks\n",
        "3. sort each block by user (or item) identities\n",
        "4. construct a scheduler\n",
        "5. launch s working threads\n",
        "6. wait until the total number of updates reaches a user-defined value\n",
        "\n",
        "\n",
        "The basic idea of SG is that, instead of expensively calculating the gradient of (1), it randomly selects a $(u,v)$ entry from the summation and calculates the corresponding gradient [Robbins and Monro 1951; Kiefer and Wolfowitz 1952]. Once $r_{u,v}$ is chosen, the objective function in (1), is:\n",
        "\n",
        "$$ f(p_u, q_v; r_{u,v}) + \\mu_p p_u + \\mu_q q_v +\n",
        "\\frac{λ_p}{2} p_u^T p_u + \\frac{λ_q}{2} q_v^T q_v \\ \\ \\ (2)\n",
        "$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "We calculate the sub-gradient over $p_u$ and $q_v$. Variables are updated by the following rules:\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$\n",
        "p_u ← p_u + γ (\\frac{d}{dp_u}(2)),  \\\\\n",
        "q_v ← q_v + γ (\\frac{d}{dq_v}(2))\n",
        "$$\n",
        "\n",
        "where $\\gamma$ is the learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkFNJJX1ZuZ2",
        "colab_type": "text"
      },
      "source": [
        "### Loss Functions\n",
        "\n",
        " $f(·)$ is a non-convex loss function of $p_u$ and $q_v$, and $\\mu_p$, $\\mu_q$, $\\lambda_p$, and $\\lambda_q$ are regularization coefficients. For Real Valued MF, the loss function can be a squared loss, an absolute loss, or generalized KL-divergence. If R is a binary matrix, users may select among logistic loss, hinge loss, and squared hinge loss to perform BMF. Note that, the non-negative constraints,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-avBcjXobjcU",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w6Zb_FgcdbA",
        "colab_type": "text"
      },
      "source": [
        "### Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UivkBvXscfkZ",
        "colab_type": "text"
      },
      "source": [
        "### Exploding Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4iX2v_FWELb",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow and Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyYLn_gfaJlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia5j8_JaXgnK",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCEC_wFz4bw3",
        "colab_type": "text"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydPWDMJf4hPH",
        "colab_type": "text"
      },
      "source": [
        "#### Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdhB21Wn2zov",
        "colab_type": "text"
      },
      "source": [
        "RNN for Short-Term Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtD9RRf0Xj-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "print(\"Tensorflow version: \" + tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHuOUZub27ny",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Display utilities [RUN ME]\n",
        "\n",
        "from enum import IntEnum\n",
        "import numpy as np\n",
        "\n",
        "class Waveforms(IntEnum):\n",
        "    SINE1 = 0\n",
        "    SINE2 = 1\n",
        "    SINE3 = 2\n",
        "    SINE4 = 3\n",
        "\n",
        "def create_time_series(waveform, datalen):\n",
        "    # Generates a sequence of length datalen\n",
        "    # There are three available waveforms in the Waveforms enum\n",
        "    # good waveforms\n",
        "    frequencies = [(0.2, 0.15), (0.35, 0.3), (0.6, 0.55), (0.4, 0.25)]\n",
        "    freq1, freq2 = frequencies[waveform]\n",
        "    noise = [np.random.random()*0.2 for i in range(datalen)]\n",
        "    x1 = np.sin(np.arange(0,datalen) * freq1)  + noise\n",
        "    x2 = np.sin(np.arange(0,datalen) * freq2)  + noise\n",
        "    x = x1 + x2\n",
        "    return x.astype(np.float32)\n",
        "\n",
        "from matplotlib import transforms as plttrans\n",
        "\n",
        "plt.rcParams['figure.figsize']=(16.8,6.0)\n",
        "plt.rcParams['axes.grid']=True\n",
        "plt.rcParams['axes.linewidth']=0\n",
        "plt.rcParams['grid.color']='#DDDDDD'\n",
        "plt.rcParams['axes.facecolor']='white'\n",
        "plt.rcParams['xtick.major.size']=0\n",
        "plt.rcParams['ytick.major.size']=0\n",
        "\n",
        "def picture_this_1(data, datalen):\n",
        "    plt.subplot(211)\n",
        "    plt.plot(data[datalen-512:datalen+512])\n",
        "    plt.axvspan(0, 512, color='black', alpha=0.06)\n",
        "    plt.axvspan(512, 1024, color='grey', alpha=0.04)\n",
        "    plt.subplot(212)\n",
        "    plt.plot(data[3*datalen-512:3*datalen+512])\n",
        "    plt.axvspan(0, 512, color='grey', alpha=0.04)\n",
        "    plt.axvspan(512, 1024, color='black', alpha=0.06)\n",
        "    plt.show()\n",
        "    \n",
        "def picture_this_2(data, batchsize, seqlen):\n",
        "    samples = np.reshape(data, [-1, batchsize, seqlen])\n",
        "    rndsample = samples[np.random.choice(samples.shape[0], 8, replace=False)]\n",
        "    print(\"Tensor shape of a batch of training sequences: \" + str(rndsample[0].shape))\n",
        "    print(\"Random excerpt:\")\n",
        "    subplot = 241\n",
        "    for i in range(8):\n",
        "        plt.subplot(subplot)\n",
        "        plt.plot(rndsample[i, 0]) # first sequence in random batch\n",
        "        subplot += 1\n",
        "    plt.show()\n",
        "    \n",
        "def picture_this_3(predictions, evaldata, evallabels, seqlen):\n",
        "    subplot = 241\n",
        "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "    for i in range(8):\n",
        "        plt.subplot(subplot)\n",
        "        #k = int(np.random.rand() * evaldata.shape[0])\n",
        "        l0, = plt.plot(evaldata[i, 1:], label=\"data\")\n",
        "        plt.plot([seqlen-2, seqlen-1], evallabels[i, -2:])\n",
        "        l1, = plt.plot([seqlen-1], [predictions[i]], \"o\", color=\"red\", label='Predicted')\n",
        "        l2, = plt.plot([seqlen-1], [evallabels[i][-1]], \"o\", color=colors[1], label='Ground Truth')\n",
        "        if i==0:\n",
        "            plt.legend(handles=[l0, l1, l2])\n",
        "        subplot += 1\n",
        "    plt.show()\n",
        "    \n",
        "def picture_this_hist(rmse1, rmse2, rmse3, rmse):\n",
        "  colors = ['#4285f4', '#34a853', '#fbbc05', '#ea4334']\n",
        "  plt.figure(figsize=(5,4))\n",
        "  plt.xticks(rotation='40')\n",
        "  plt.title('RMSE: your model vs. simplistic approaches')\n",
        "  plt.bar(['RND', 'LAST', 'LAST2', 'Yours'], [rmse1, rmse2, rmse3, rmse], color=colors)\n",
        "  plt.show()\n",
        "\n",
        "def picture_this_hist_all(rmse1, rmse2, rmse3, rmse4, rmse5, rmse6, rmse7, rmse8):\n",
        "  colors = ['#4285f4', '#34a853', '#fbbc05', '#ea4334', '#4285f4', '#34a853', '#fbbc05', '#ea4334']\n",
        "  plt.figure(figsize=(7,4))\n",
        "  plt.xticks(rotation='40')\n",
        "  plt.ylim(0, 0.35)\n",
        "  plt.title('RMSE: all models')\n",
        "  plt.bar(['RND', 'LAST', 'LAST2', 'LINEAR', 'DNN', 'CNN', 'RNN', 'RNN_N'],\n",
        "          [rmse1, rmse2, rmse3, rmse4, rmse5, rmse6, rmse7, rmse8], color=colors)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCr691hT3Bnx",
        "colab_type": "text"
      },
      "source": [
        "Generate Fake Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DIlFYT83A3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_SEQ_LEN = 1024*128\n",
        "data = np.concatenate([create_time_series(waveform, DATA_SEQ_LEN) for waveform in Waveforms]) # 4 different wave forms\n",
        "picture_this_1(data, DATA_SEQ_LEN)\n",
        "DATA_LEN = DATA_SEQ_LEN * 4 # since we concatenated 4 sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmZ1kGsi3FEx",
        "colab_type": "text"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBh1cUHS3GGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RNN_CELLSIZE = 32   # size of the RNN cells\n",
        "SEQLEN = 32         # unrolled sequence length\n",
        "BATCHSIZE = 32      # mini-batch size\n",
        "LAST_N = SEQLEN//2  # loss computed on last N element of sequence in advanced RNN model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkWC9wPP3JBA",
        "colab_type": "text"
      },
      "source": [
        "Visualize Training Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5aFmYH3KFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "picture_this_2(data, BATCHSIZE, SEQLEN) # execute multiple times to see different sample sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl4HORqh3OJ1",
        "colab_type": "text"
      },
      "source": [
        "Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CobkBsfj3P08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is how to create a Keras model from neural network layers\n",
        "def compile_keras_sequential_model(list_of_layers, msg):\n",
        "  \n",
        "    # a tf.keras.Sequential model is a sequence of layers\n",
        "    model = tf.keras.Sequential(list_of_layers)\n",
        "    \n",
        "    # keras does not have a pre-defined metric for Root Mean Square Error. Let's define one.\n",
        "    def rmse(y_true, y_pred): # Root Mean Squared Error\n",
        "      return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
        "    \n",
        "    print('\\nModel ', msg)\n",
        "    \n",
        "    # to finalize the model, specify the loss, the optimizer and metrics\n",
        "    model.compile(\n",
        "       loss = 'mean_squared_error',\n",
        "       optimizer = 'rmsprop',\n",
        "       metrics = [rmse])\n",
        "    \n",
        "    # this prints a description of the model\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "  \n",
        "#\n",
        "# three very simplistic \"models\" that require no training. Can you beat them ?\n",
        "#\n",
        "\n",
        "# SIMPLISTIC BENCHMARK MODEL 1\n",
        "predict_same_as_last_value = lambda x: x[:,-1] # shape of x is [BATCHSIZE,SEQLEN]\n",
        "# SIMPLISTIC BENCHMARK MODEL 2\n",
        "predict_trend_from_last_two_values = lambda x: x[:,-1] + (x[:,-1] - x[:,-2])\n",
        "# SIMPLISTIC BENCHMARK MODEL 3\n",
        "predict_random_value = lambda x: tf.random.uniform(tf.shape(x)[0:1], -2.0, 2.0)\n",
        "\n",
        "def model_layers_from_lambda(lambda_fn, input_shape, output_shape):\n",
        "  return [tf.keras.layers.Lambda(lambda_fn, input_shape=input_shape),\n",
        "          tf.keras.layers.Reshape(output_shape)]\n",
        "\n",
        "model_layers_RAND  = model_layers_from_lambda(predict_random_value,               input_shape=[SEQLEN,], output_shape=[1,])\n",
        "model_layers_LAST  = model_layers_from_lambda(predict_same_as_last_value,         input_shape=[SEQLEN,], output_shape=[1,])\n",
        "model_layers_LAST2 = model_layers_from_lambda(predict_trend_from_last_two_values, input_shape=[SEQLEN,], output_shape=[1,])\n",
        "\n",
        "# three neural network models for comparison, in increasing order of complexity\n",
        "\n",
        "l = tf.keras.layers  # syntax shortcut\n",
        "\n",
        "# BENCHMARK MODEL 4: linear model (RMSE: 0.215 after 10 epochs)\n",
        "model_layers_LINEAR = [l.Dense(1, input_shape=[SEQLEN,])] # output shape [BATCHSIZE, 1]\n",
        "\n",
        "# BENCHMARK MODEL 5: 2-layer dense model (RMSE: 0.197 after 10 epochs)\n",
        "model_layers_DNN = [l.Dense(SEQLEN//2, activation='relu', input_shape=[SEQLEN,]), # input  shape [BATCHSIZE, SEQLEN]\n",
        "                    l.Dense(1)] # output shape [BATCHSIZE, 1]\n",
        "\n",
        "# BENCHMARK MODEL 6: convolutional (RMSE: 0.186 after 10 epochs)\n",
        "model_layers_CNN = [\n",
        "    l.Reshape([SEQLEN, 1], input_shape=[SEQLEN,]), # [BATCHSIZE, SEQLEN, 1] is necessary for conv model\n",
        "    l.Conv1D(filters=8, kernel_size=4, activation='relu', padding=\"same\"), # [BATCHSIZE, SEQLEN, 8]\n",
        "    l.Conv1D(filters=16, kernel_size=3, activation='relu', padding=\"same\"), # [BATCHSIZE, SEQLEN, 8]\n",
        "    l.Conv1D(filters=8, kernel_size=1, activation='relu', padding=\"same\"), # [BATCHSIZE, SEQLEN, 8]\n",
        "    l.MaxPooling1D(pool_size=2, strides=2),  # [BATCHSIZE, SEQLEN//2, 8]\n",
        "    l.Conv1D(filters=8, kernel_size=3, activation='relu', padding=\"same\"),  # [BATCHSIZE, SEQLEN//2, 8]\n",
        "    l.MaxPooling1D(pool_size=2, strides=2),  # [BATCHSIZE, SEQLEN//4, 8]\n",
        "    # mis-using a conv layer as linear regression :-)\n",
        "    l.Conv1D(filters=1, kernel_size=SEQLEN//4, activation=None, padding=\"valid\"), # output shape [BATCHSIZE, 1, 1]\n",
        "    l.Reshape([1,]) ] # output shape [BATCHSIZE, 1]\n",
        "\n",
        "# RNN\n",
        "model_layers_RNN = [\n",
        "    # input shape needed on first layer only\n",
        "    l.Reshape([SEQLEN, 1], input_shape=[SEQLEN,]),\n",
        "    l.GRU(RNN_CELLSIZE), # shape [BATCHSIZE, RNN_CELLSIZE]\n",
        "    l.Dense(1, ) # shape [BATCHSIZE, 1]\n",
        "    \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLdkfDMu4nDI",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgNbYk6r4oyT",
        "colab_type": "text"
      },
      "source": [
        "### Architecture"
      ]
    }
  ]
}